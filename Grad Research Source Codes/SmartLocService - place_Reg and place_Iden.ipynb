{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run these codes FIRST each time before using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_reg(df1, df2, df3, df4, df5):\n",
    "    #Creates a registration list from 5 measurement files of SSID-RSSI\n",
    "    #NOTEs:\n",
    "        #Takes 5 Pandas DataFrames as input arguments and MUST have header: SSID and RSSI\n",
    "        #Output returns Registration List (reg_list) to be used in place-iden() OR Comparison List\n",
    "    \n",
    "    #Filtering out unique SSIDs from all datasets\n",
    "    dfs = [df1, df2, df3, df4, df5]\n",
    "    SSID_sets = [set(df['SSID']) for df in dfs]\n",
    "    duplicated_SSIDs = set.intersection(*SSID_sets)\n",
    "    dfs_filtered = [df[df['SSID'].isin(duplicated_SSIDs)] for df in dfs]\n",
    "\n",
    "    #Calling the filtered dataset (M: Measurement data)\n",
    "    M1 = dfs_filtered[0]\n",
    "    M2 = dfs_filtered[1]\n",
    "    M3 = dfs_filtered[2]\n",
    "    M4 = dfs_filtered[3]\n",
    "    M5 = dfs_filtered[4]\n",
    "    \n",
    "    #Sort SSID Column from alphabetically (A-Z)\n",
    "    M1_sorted = M1.sort_values(by=['SSID'])\n",
    "    M2_sorted = M2.sort_values(by=['SSID'])\n",
    "    M3_sorted = M3.sort_values(by=['SSID'])\n",
    "    M4_sorted = M4.sort_values(by=['SSID'])\n",
    "    M5_sorted = M5.sort_values(by=['SSID'])\n",
    "\n",
    "    #Reset index of all datasets\n",
    "    M1_sorted = M1_sorted.reset_index(drop=True, inplace=False)\n",
    "    M2_sorted = M2_sorted.reset_index(drop=True, inplace=False)\n",
    "    M3_sorted = M3_sorted.reset_index(drop=True, inplace=False)\n",
    "    M4_sorted = M4_sorted.reset_index(drop=True, inplace=False)\n",
    "    M5_sorted = M5_sorted.reset_index(drop=True, inplace=False)\n",
    "    \n",
    "    #Drop SSID column from 2nd - 5th datasets\n",
    "    M2_RSSI = M2_sorted.drop(['SSID'],axis=1)\n",
    "    M3_RSSI = M3_sorted.drop(['SSID'],axis=1)\n",
    "    M4_RSSI = M4_sorted.drop(['SSID'],axis=1)\n",
    "    M5_RSSI = M5_sorted.drop(['SSID'],axis=1)\n",
    "    \n",
    "    #Concatenate all datasets, column-by-column\n",
    "    dataset = pd.concat([M1_sorted, M2_RSSI, M3_RSSI, M4_RSSI, M5_RSSI], axis=1)\n",
    "\n",
    "    #Creating \"mean\" column = mean of each row\n",
    "    dataset['mean'] = dataset.mean(axis=1)\n",
    "\n",
    "    #Creating the registration list\n",
    "    reg_list = dataset[['SSID', 'mean']].copy()\n",
    "    \n",
    "    return reg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_reg2(df1, df2, df3, df4, df5, df6, df7, df8, df9, df10):\n",
    "    #Creates a registration list from 10 measurement files of SSID-RSSI\n",
    "    #NOTEs:\n",
    "        #Takes 10 Pandas DataFrames as input arguments and MUST have header: SSID and RSSI\n",
    "        #Output returns Registration List (reg_list) to be used in place-iden() OR Comparison List\n",
    "    \n",
    "    #Filtering out unique SSIDs from all datasets\n",
    "    dfs = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]\n",
    "    SSID_sets = [set(df['SSID']) for df in dfs]\n",
    "    duplicated_SSIDs = set.intersection(*SSID_sets)\n",
    "    dfs_filtered = [df[df['SSID'].isin(duplicated_SSIDs)] for df in dfs]\n",
    "\n",
    "    #Calling the filtered dataset (M: Measurement data)\n",
    "    M1 = dfs_filtered[0]\n",
    "    M2 = dfs_filtered[1]\n",
    "    M3 = dfs_filtered[2]\n",
    "    M4 = dfs_filtered[3]\n",
    "    M5 = dfs_filtered[4]\n",
    "    M6 = dfs_filtered[5]\n",
    "    M7 = dfs_filtered[6]\n",
    "    M8 = dfs_filtered[7]\n",
    "    M9 = dfs_filtered[8]\n",
    "    M10 = dfs_filtered[9]\n",
    "    \n",
    "    #Sort SSID Column from alphabetically (A-Z)\n",
    "    M1_sorted = M1.sort_values(by=['SSID'])\n",
    "    M2_sorted = M2.sort_values(by=['SSID'])\n",
    "    M3_sorted = M3.sort_values(by=['SSID'])\n",
    "    M4_sorted = M4.sort_values(by=['SSID'])\n",
    "    M5_sorted = M5.sort_values(by=['SSID'])\n",
    "    M6_sorted = M6.sort_values(by=['SSID'])\n",
    "    M7_sorted = M7.sort_values(by=['SSID'])\n",
    "    M8_sorted = M8.sort_values(by=['SSID'])\n",
    "    M9_sorted = M9.sort_values(by=['SSID'])\n",
    "    M10_sorted = M10.sort_values(by=['SSID'])\n",
    "\n",
    "    #Reset index of all datasets\n",
    "    M1_sorted = M1_sorted.reset_index(drop=True, inplace=False)\n",
    "    M2_sorted = M2_sorted.reset_index(drop=True, inplace=False)\n",
    "    M3_sorted = M3_sorted.reset_index(drop=True, inplace=False)\n",
    "    M4_sorted = M4_sorted.reset_index(drop=True, inplace=False)\n",
    "    M5_sorted = M5_sorted.reset_index(drop=True, inplace=False)\n",
    "    M6_sorted = M6_sorted.reset_index(drop=True, inplace=False)\n",
    "    M7_sorted = M7_sorted.reset_index(drop=True, inplace=False)\n",
    "    M8_sorted = M8_sorted.reset_index(drop=True, inplace=False)\n",
    "    M9_sorted = M9_sorted.reset_index(drop=True, inplace=False)\n",
    "    M10_sorted = M10_sorted.reset_index(drop=True, inplace=False)\n",
    "    \n",
    "    #Drop SSID column from 2nd - 10th datasets\n",
    "    M2_RSSI = M2_sorted.drop(['SSID'],axis=1)\n",
    "    M3_RSSI = M3_sorted.drop(['SSID'],axis=1)\n",
    "    M4_RSSI = M4_sorted.drop(['SSID'],axis=1)\n",
    "    M5_RSSI = M5_sorted.drop(['SSID'],axis=1)\n",
    "    M6_RSSI = M6_sorted.drop(['SSID'],axis=1)\n",
    "    M7_RSSI = M7_sorted.drop(['SSID'],axis=1)\n",
    "    M8_RSSI = M8_sorted.drop(['SSID'],axis=1)\n",
    "    M9_RSSI = M9_sorted.drop(['SSID'],axis=1)\n",
    "    M10_RSSI = M10_sorted.drop(['SSID'],axis=1)\n",
    "    \n",
    "    #Concatenate all datasets, column-by-column\n",
    "    dataset = pd.concat([M1_sorted, M2_RSSI, M3_RSSI, M4_RSSI, M5_RSSI, M6_RSSI, M7_RSSI, M8_RSSI, M9_RSSI, M10_RSSI], axis=1)\n",
    "\n",
    "    #Creating \"mean\" column = mean of each row\n",
    "    dataset['mean'] = dataset.mean(axis=1)\n",
    "\n",
    "    #Creating the registration list\n",
    "    reg_list = dataset[['SSID', 'mean']].copy()\n",
    "    \n",
    "    return reg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_iden(registrationList, comparisonList, R_margin=10, P_th=50):\n",
    "    #Identifies whether a place is registered or not\n",
    "    #NOTEs: \n",
    "        #Comparison List (CL) and Registration List (RL) are assumed to be Pandas DataFrame\n",
    "        #Default R_margin and P_th are based on SmartLocService paper\n",
    "    \n",
    "    #Create 2 column table: SSID-RSSI\n",
    "    r = registrationList.filter(['SSID','mean'])\n",
    "    c = comparisonList.filter(['SSID','RSSI'])\n",
    "    \n",
    "    #Convert each column in Pandas DataFrame to list + convert RSSI values to float\n",
    "    rgs_SSID = r['SSID'].to_list()\n",
    "    r1 = r['mean'].to_list()\n",
    "    rgs_RSSI = [float(i) for i in r1]\n",
    "    cmp_SSID = c['SSID'].to_list()\n",
    "    r2 = c['RSSI'].to_list()\n",
    "    cmp_RSSI = [float(i) for i in r2]\n",
    "    \n",
    "    #Convert 2 lists (SSID & RSSI) to dictionary\n",
    "    rgs_dict = dict(zip(rgs_SSID,rgs_RSSI))\n",
    "    cmp_dict = dict(zip(cmp_SSID,cmp_RSSI))\n",
    "    \n",
    "    #Finding common SSIDs by observation:\n",
    "    P_num = []\n",
    "    \n",
    "    for SSID in cmp_dict:\n",
    "        if SSID in rgs_dict:\n",
    "            R_ave = rgs_dict[SSID] #Average RSSI value of each SSID AFTER multi-measurements within time T_A @ RL\n",
    "            R_auth = cmp_dict[SSID] #Instantaneous RSSI value of each SSID @ CL\n",
    "            \n",
    "    #Finding common SSIDs that satisfies:\n",
    "        #R_ave-R_margin <= R_auth <= R_ave+R_margin\n",
    "            if R_auth >= (R_ave - R_margin) and R_auth <= (R_ave + R_margin):\n",
    "                P_num.append(SSID) #Corresponding RSSI\n",
    "                    \n",
    "    print(len(P_num), 'common SSID(s) satisfy the equation.')\n",
    "    print('SSID name(s):', P_num)\n",
    "\n",
    "    #Computing concordance rate P\n",
    "    P = len(P_num) / len(cmp_SSID) * 100\n",
    "    print('The concordance rate is', P)\n",
    "        \n",
    "    #Comparing P and threshold P    \n",
    "    if P >= P_th:\n",
    "        print('This place is registered. I know this place.')\n",
    "        #Save results to a csv file\n",
    "        results= [P_th, R_margin, len(P_num), P, True]\n",
    "        with open('out.csv', 'a+', newline='') as write_obj:\n",
    "            # Create a writer object from csv module\n",
    "            csv_writer = writer(write_obj)\n",
    "            # Add contents of list as last row in the csv file\n",
    "            csv_writer.writerow(results)\n",
    "    else:\n",
    "        print('This place is unregistered. Where am I?')\n",
    "        results= [P_th, R_margin, len(P_num), P, False]\n",
    "        with open('out.csv', 'a+', newline='') as write_obj:\n",
    "            # Create a writer object from csv module\n",
    "            csv_writer = writer(write_obj)\n",
    "            # Add contents of list as last row in the csv file\n",
    "            csv_writer.writerow(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Example measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD SSID-RSSI measurement datasets (txt -> csv)\n",
    "    #SSID-RSSI measurement using iOS airport function via meas.sh (see READ_ME)\n",
    "data1 = pd.read_csv('automeasure/result1.txt', sep=' ', header=None, names= ['SSID','RSSI'])\n",
    "data2 = pd.read_csv('automeasure/result2.txt', sep=' ', header=None, names= ['SSID','RSSI'])\n",
    "data3 = pd.read_csv('automeasure/result3.txt', sep=' ', header=None, names= ['SSID','RSSI'])\n",
    "data4 = pd.read_csv('automeasure/result4.txt', sep=' ', header=None, names= ['SSID','RSSI'])\n",
    "data5 = pd.read_csv('automeasure/result5.txt', sep=' ', header=None, names= ['SSID','RSSI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN place_reg() to get Registration List (RL)\n",
    "rgs = place_reg(data1,data2,data3,data4,data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OPTIONAL: Check if rgs is a dataframe or not\n",
    "isinstance(rgs,pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD Comparison List (CL) dataset (CL needs to be in csv format)\n",
    "    # CL is created the same way as RL using place_reg\n",
    "cmp = pd.read_csv('data3(5-14).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 common SSID(s) satisfy the equation.\n",
      "SSID name(s): ['vf300-f8fc15-gw']\n",
      "The concordance rate is 8.333333333333332\n",
      "This place is unregistered. Where am I?\n"
     ]
    }
   ],
   "source": [
    "#RUN place_iden4()\n",
    "place_iden(rgs,cmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
